{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c8e00c2",
   "metadata": {},
   "source": [
    "# Generate Output\n",
    "This notebook will read in the metadata from the [Arquin Spreadsheet](https://docs.google.com/spreadsheets/d/1LRbios7yQRo3aqCh0Es2Wiae_dicg_OtL-_yqP-Tb8I/edit#gid=1718343431) and product an output for ingestion into Omeka "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00635c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata spreadsheet URL\n",
    "url = 'https://docs.google.com/spreadsheets/d/1LRbios7yQRo3aqCh0Es2Wiae_dicg_OtL-_yqP-Tb8I/edit#gid=1718343431'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a6e2f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get definitions\n",
    "%run definitions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f61b2bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run predefined functions\n",
    "%run functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf40876",
   "metadata": {},
   "source": [
    "## Define the Output Columns and labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a70f5d",
   "metadata": {},
   "source": [
    "## import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c70bcf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "from gsheets import Sheets\n",
    "from datetime import datetime\n",
    "import functools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd603f5",
   "metadata": {},
   "source": [
    "## Load the spreadsheet information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edae7a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if HttpAccessTokenRefreshError, close everything and start over\n",
    "sheets = Sheets.from_files('~/client_secrets.json', '~/storage.json')\n",
    "s = sheets.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "0b1fe81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the translations spreadsheet\n",
    "translations = s.find('Translations').to_frame()\n",
    "# translations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e40a2990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid boxes with metadata are: [1, 2, 3, 4, 5, 7, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69]\n"
     ]
    }
   ],
   "source": [
    "# get the list of boxes containing metadata\n",
    "\n",
    "box_list = []\n",
    "box_list_sheets = s.sheets.titles()\n",
    "\n",
    "for b in box_list_sheets:\n",
    "    if 'Box' in b:\n",
    "        box_list.append(int(b[4:]))\n",
    "        \n",
    "print(f'valid boxes with metadata are: {box_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aaa8eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use_box = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9047e3e",
   "metadata": {},
   "source": [
    "## Load Arquin Metadata with validated Subjects for parsing subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e73de1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16294 of 16295: search_media = Arquin_069_0217.jpg\n"
     ]
    }
   ],
   "source": [
    "# output will be the dataframe: df, which has the validated subjects\n",
    "%run arquin_metadata_subjects_review_final.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3351aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the translation data\n",
    "title_translations = s.find('unique_titles_06142022').to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b0c2bc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'use_box' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# x will be the data from the box specified\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m x \u001B[38;5;241m=\u001B[39m return_box(box_list[\u001B[43muse_box\u001B[49m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'use_box' is not defined"
     ]
    }
   ],
   "source": [
    "# x will be the data from the box specified\n",
    "# x = return_box(box_list[use_box])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9037562c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try to return all the boxes \n",
    "\n",
    "combined_box_data = []\n",
    "for i, box_number in enumerate(box_list):\n",
    "    one_box = return_box(box_number)\n",
    "    combined_box_data.append(one_box)\n",
    "\n",
    "box_data = pd.concat(combined_box_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d4cc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# strip leading and trailing space \n",
    "box_data['title'] = box_data['title'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc61d5c4",
   "metadata": {},
   "source": [
    "### Get the list of Identifiers by Box Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04c508b1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "box_with_trans = box_data.merge(title_translations, how='left', left_on='title', right_on='Title', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26b77a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_with_trans = box_with_trans.rename(\n",
    "    columns={\n",
    "        'Translation ES': 'title_ES',\n",
    "        'Translation PT': 'title_PT'\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fdbb63b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# join in the subjects from df\n",
    "box_with_trans_and_subjects = box_with_trans.merge(df, on=['media'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f0a189",
   "metadata": {},
   "source": [
    "## Rename the columns post join "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6a731026",
   "metadata": {},
   "outputs": [],
   "source": [
    "box_with_trans_and_subjects = box_with_trans_and_subjects.rename(columns={'identifier_x': 'identifier', \n",
    "'media': 'media', \n",
    "'title_x': 'title', \n",
    "'subject_x': 'subject', \n",
    "'description_x': 'description', \n",
    "'creator_x': 'creator', \n",
    "'publisher_x': 'publisher', \n",
    "'date_x': 'date', \n",
    "'rights_x': 'rights', \n",
    "'language_x': 'language', \n",
    "'relation_x': 'relation', \n",
    "'format_x': 'format', \n",
    "'type_x': 'type', \n",
    "'coverage_x': 'coverage', \n",
    "'spatial_x': 'spatial', \n",
    "'Index': 'Index', \n",
    "'Title': 'Title', \n",
    "'Translation ES': 'title_ES', \n",
    "'Translation PT': 'title_PT', \n",
    "'_merge': '_merge', \n",
    "'identifier_y': 'identifier_y', \n",
    "'title_y': 'title_y', \n",
    "'subject_y': 'subject_y', \n",
    "'description_y': 'description_y', \n",
    "'creator_y': 'creator_y', \n",
    "'publisher_y': 'publisher_y', \n",
    "'date_y': 'date_y', \n",
    "'rights_y': 'rights_y', \n",
    "'language_y': 'language_y', \n",
    "'relation_y': 'relation_y', \n",
    "'format_y': 'format_y', \n",
    "'type_y': 'type_y', \n",
    "'coverage_y': 'coverage_y', \n",
    "'spatial_y': 'spatial_y', \n",
    "'subjects': 'subjects', \n",
    "'join_concept': 'join_concept', \n",
    "'extra_notes': 'extra_notes', \n",
    "'unnamed: 2': 'unnamed: 2', \n",
    "'unnamed: 4': 'unnamed: 4', \n",
    "'AACR2_FLAG': 'AACR2_FLAG', \n",
    "'DISPLAY_DATE': 'DISPLAY_DATE', \n",
    "'DISPLAY_NAME': 'DISPLAY_NAME', \n",
    "'DISPLAY_ORDER': 'DISPLAY_ORDER', \n",
    "'END_DATE': 'END_DATE', \n",
    "'HISTORIC_FLAG': 'HISTORIC_FLAG', \n",
    "'OTHER_FLAGS': 'OTHER_FLAGS', \n",
    "'PREFERRED_x': 'PREFERRED', \n",
    "'START_DATE': 'START_DATE', \n",
    "'SUBJECT_ID_x': 'SUBJECT_ID', \n",
    "'TERM': 'TERM', \n",
    "'TERM_ID': 'TERM_ID', \n",
    "'VERNACULAR': 'VERNACULAR', \n",
    "'LANGUAGE_CODE': 'LANGUAGE_CODE', \n",
    "'PREFERRED_y': 'PREFERRED_y', \n",
    "'SUBJECT_ID_y': 'SUBJECT_ID_y', \n",
    "'QUALIFIER': 'QUALIFIER', \n",
    "'TERM_TYPE': 'TERM_TYPE', \n",
    "'PART_OF_SPEECH': 'PART_OF_SPEECH', \n",
    "'LANG_STAT': 'LANG_STAT', \n",
    "'full_concept': 'full_concept', \n",
    "'use_concept': 'use_concept', \n",
    "'BoxId': 'BoxId', \n",
    "'Unnamed: 0': 'Unnamed: 0', \n",
    "'color': 'color', \n",
    "'RGB': 'RGB'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fee978b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # this is a test - you should delete it\n",
    "# box_with_trans_and_subjects[box_with_trans_and_subjects['identifier'] == 'A-4 104'][['identifier', 'media', 'join_concept', 'use_concept', 'BoxId']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5630f24c",
   "metadata": {},
   "source": [
    "## Generate a distinct list of subjects for the box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0360add2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_29264/3168744551.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(file_path\n",
      "/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_29264/3168744551.py:2: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(file_path\n",
      "b'Skipping line 451800: expected 13 fields, saw 14\\n'\n",
      "/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_29264/3168744551.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path\n",
      "/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_29264/3168744551.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(file_path\n",
      "/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_29264/3168744551.py:2: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(file_path\n",
      "b'Skipping line 466042: expected 8 fields, saw 9\\nSkipping line 468123: expected 8 fields, saw 9\\n'\n"
     ]
    }
   ],
   "source": [
    "%run subject_translations.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ce19df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_dist = box_with_trans_and_subjects[['SUBJECT_ID', 'TERM_ID', 'use_concept']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "56bd7f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_dist = pd.merge(subjects_dist, lt_all, on=['SUBJECT_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a50bcba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_dist = box_with_trans_and_subjects[['SUBJECT_ID', 'TERM_ID', 'use_concept']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fd3c4e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_dist = pd.merge(subjects_dist, lt_all, on=['SUBJECT_ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fd3ae84",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjects_trans_headings = [\n",
    "    'SUBJECT_ID', 'TERM_ID'\n",
    "    , 'use_concept'\n",
    "    , 'term_id_english',\n",
    "    'term_id_spanish', 'term_spanish', 'qualifier_spanish',\n",
    "    'term_id_port', 'term_port', 'qualifier_port'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e89d457",
   "metadata": {},
   "source": [
    "## Generate a distinct list of subjects for the box"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0680760b",
   "metadata": {},
   "source": [
    "## Create the Combination Columns for Subjects (eventually also translations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6a97f3",
   "metadata": {},
   "source": [
    "### example with  a single record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63018d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bts_comb =  bts_ss.groupby(['identifier', 'subject'])['use_concept'].apply(lambda x: ';'.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36347ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bts_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41ac7916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bts_comb =  bts_ss.groupby(['identifier', 'subject'])['SUBJECT_ID'].apply(lambda x: ';'.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1228cdf0",
   "metadata": {},
   "source": [
    "### remove any use_concept records that are NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c3c6600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>media</th>\n",
       "      <th>subject</th>\n",
       "      <th>use_concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [identifier, media, subject, use_concept]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "box_with_trans_and_subjects[box_with_trans_and_subjects['use_concept'].isna()][['identifier','media','subject','use_concept']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "749e0da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bts = box_with_trans_and_subjects.dropna(subset=['use_concept'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4676495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bts = box_with_trans_and_subjects.dropna(subset=['SUBJECT_ID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48bf0fd",
   "metadata": {},
   "source": [
    "### having dropped NaN use_concepts, create the DF with the combined subjects\n",
    "schema is identifier, use_concepts (combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "25e3ffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bts_combined_subjects = bts.groupby(['identifier'])['use_concept'].apply(lambda x: '; '.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "620cb055",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test_subj = bts_combined_subjects.merge(box_with_trans_and_subjects, on='identifier')\n",
    "# x.merge(title_translations, how='left', left_on='title', right_on='Title', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3e0c54f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bts_combined_subject_ids = bts.groupby(['identifier'])['SUBJECT_ID'].apply(lambda x: '; '.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7872facc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put in a rename for the bts_combined_subject_ids so that the final join doesn't have two SUBJECT_ID_y columns\n",
    "bts_combined_subject_ids = bts_combined_subject_ids.rename(\n",
    "    columns={\n",
    "        'identifier': 'identifier',\n",
    "        'SUBJECT_ID': 'subject_id_comb_en'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c4cac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test = output_test_subj.merge(bts_combined_subject_ids, on='identifier')\n",
    "# x.merge(title_translations, how='left', left_on='title', right_on='Title', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c41453f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test_subj = bts_combined_subjects.merge(box_with_trans_and_subjects, on='identifier')\n",
    "# x.merge(title_translations, how='left', left_on='title', right_on='Title', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e89cca70",
   "metadata": {},
   "outputs": [],
   "source": [
    "bts_combined_subject_ids = bts.groupby(['identifier'])['SUBJECT_ID'].apply(lambda x: '; '.join(x)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6c4c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put in a rename for the bts_combined_subject_ids so that the final join doesn't have two SUBJECT_ID_y columns\n",
    "bts_combined_subject_ids = bts_combined_subject_ids.rename(\n",
    "    columns={\n",
    "        'identifier': 'identifier',\n",
    "        'SUBJECT_ID': 'subject_id_comb_en',\n",
    "#         'SUBJECT_ID': 'subject_id_comb_es'        \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7487f8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test = output_test_subj.merge(bts_combined_subject_ids, on='identifier')\n",
    "# x.merge(title_translations, how='left', left_on='title', right_on='Title', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "55fdf354",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_test.insert(\n",
    "            loc = 2,\n",
    "          column = 'subjects_es',\n",
    "          value = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e2e59d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_no_translations = output_test[output+['subject_id_comb_en']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041eecd5",
   "metadata": {},
   "source": [
    "## This will be the script for outputting the file to the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d5c5320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_output[output].to_csv(\n",
    "#     path_or_buf='./csv_files/output_file_box2.csv',\n",
    "#     index=False, header=dc_output,\n",
    "#     quoting=csv.QUOTE_NONNUMERIC\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "35696e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://docs.google.com/spreadsheets/d/1LRbios7yQRo3aqCh0Es2Wiae_dicg_OtL-_yqP-Tb8I/edit#gid=1718343431'\n",
    "# translations_sheet = Sheets.from_files('~/client_secrets.json', '~/storage.json')\n",
    "# translations_data = translations_sheet.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "18ae8420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # delete this test\n",
    "# # translations[translations['SUBJECT_ID'] == '300423325']\n",
    "# final_output_no_translations[final_output_no_translations['subject_id_comb_en'].str.contains('300423325')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a9974973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of identifiers in the box that have non-null subject ids \n",
    "final_output_id_list = (final_output_no_translations\n",
    "                        [final_output_no_translations\n",
    "                         ['subject_id_comb_en']\n",
    "                         .notnull()]['identifier']\n",
    "                        .to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "60bfee3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations_df = None\n",
    "missing_terms_df = None\n",
    "for i, arquin_identifier in enumerate(final_output_id_list):\n",
    "    subject_identifiers = (\n",
    "        final_output_no_translations\n",
    "        [final_output_no_translations['identifier']==\n",
    "         arquin_identifier][['identifier', 'subject_id_comb_en']])\n",
    "    \n",
    "    # get the of subject ids and split them to a list    \n",
    "    subject_translations_id_list = subject_identifiers['subject_id_comb_en']\\\n",
    "    .to_list()[0]\\\n",
    "    .replace(\"''\",'')\\\n",
    "    .split(';')\n",
    "\n",
    "    # remove the leading space that sometimes results from above manipulation\n",
    "    subject_translations_id_list = [x.strip(' ') for x in subject_translations_id_list]\n",
    "    \n",
    "    # loop through the ids and get the translations, append them into the lists below for each language\n",
    "    missing_terms = []\n",
    "    en_terms = []\n",
    "    es_terms = []\n",
    "    pt_terms = []\n",
    "\n",
    "    for subject_id in subject_translations_id_list: \n",
    "        result = translations[translations['SUBJECT_ID'] == int(subject_id)][['en_term','es_term', 'pt_term']]\n",
    "        if len(result) == 0:\n",
    "            missing_terms.append(subject_id)\n",
    "        else:\n",
    "            en_terms.append(result['en_term'].iloc[0])\n",
    "            es_terms.append(result['es_term'].iloc[0])\n",
    "            pt_terms.append(result['pt_term'].iloc[0])\n",
    "    \n",
    "    if len(missing_terms) > 0:\n",
    "        missing_terms_dict = {arquin_identifier: [arquin_identifier, missing_terms]}\n",
    "        missing_terms_df_temp = pd.DataFrame.from_dict(missing_terms_dict\n",
    "                                                      , orient = 'index'\n",
    "                                                      , columns = ['identifier', 'missing_terms'])\n",
    "        \n",
    "        try:\n",
    "            missing_terms_df = pd.concat([missing_terms_df, missing_terms_df_temp])\n",
    "        except NameError:\n",
    "            missing_terms_df = missing_terms_df_temp\n",
    "\n",
    "    \n",
    "    \n",
    "    # create a dictionary for the results, which I'll use to create a dataframe\n",
    "    translation_dict = {arquin_identifier: [arquin_identifier, en_terms, es_terms, pt_terms]}\n",
    "    one_identifier_with_translations = pd.DataFrame.from_dict(translation_dict\n",
    "                                                          , orient='index'\n",
    "                                                          , columns=['identifier', 'en_term','es_term', 'pt_term']\n",
    "                                                         )\n",
    "    \n",
    "    # create columns where the translated subjects are strings instead of lists\n",
    "    one_identifier_with_translations['en_terms_string'] = [', '.join(map(str, l)) for l in one_identifier_with_translations['en_term']]\n",
    "    one_identifier_with_translations['es_terms_string'] = [', '.join(map(str, l)) for l in one_identifier_with_translations['es_term']]\n",
    "    one_identifier_with_translations['pt_terms_string'] = [', '.join(map(str, l)) for l in one_identifier_with_translations['pt_term']]\n",
    "    \n",
    "    # use the resulting df and concatenate it to the translations_df, which will be the final result\n",
    "    # use the try/except for the first iteration\n",
    "    try:\n",
    "        translations_df = pd.concat([translations_df, one_identifier_with_translations])\n",
    "    except NameError:\n",
    "        translations_df = one_identifier_with_translations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a6075abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>identifier</th>\n",
       "      <th>missing_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>B-4 50</th>\n",
       "      <td>B-4 50</td>\n",
       "      <td>[300423129]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>B-4 61</th>\n",
       "      <td>B-4 61</td>\n",
       "      <td>[300423129]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F-5 114</th>\n",
       "      <td>F-5 114</td>\n",
       "      <td>[300433380]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J-1 220</th>\n",
       "      <td>J-1 220</td>\n",
       "      <td>[300425838]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>J-1 221</th>\n",
       "      <td>J-1 221</td>\n",
       "      <td>[300425838]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-1 181</th>\n",
       "      <td>T-1 181</td>\n",
       "      <td>[300182716]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T-1 182</th>\n",
       "      <td>T-1 182</td>\n",
       "      <td>[300182716]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        identifier missing_terms\n",
       "B-4 50      B-4 50   [300423129]\n",
       "B-4 61      B-4 61   [300423129]\n",
       "F-5 114    F-5 114   [300433380]\n",
       "J-1 220    J-1 220   [300425838]\n",
       "J-1 221    J-1 221   [300425838]\n",
       "T-1 181    T-1 181   [300182716]\n",
       "T-1 182    T-1 182   [300182716]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this should be blank - otherwise, there are missing translations in this box\n",
    "missing_terms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a0548e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the above returned records, then this cell will rerturn the missing translations to the clipboard\n",
    "# once run, you can copy and paste the results to the translation spreadsheet here:\n",
    "# https://docs.google.com/spreadsheets/d/1o0cWJhnMboT67G6iWdhFVLOV-DrPWX1nUGDziN2Sj-Q/edit#gid=24132108\n",
    "\n",
    "if len(missing_terms_df) > 0:\n",
    "\n",
    "    missing_terms_list = missing_terms_df['identifier'].to_list()\n",
    "\n",
    "    more_trans_combined = pd.DataFrame()\n",
    "    for x in missing_terms_list:\n",
    "        terms_missing = missing_terms_df[missing_terms_df['identifier'] == x]['missing_terms'].to_list()[0]\n",
    "        for term in terms_missing:\n",
    "            more_trans = lt_all[lt_all['SUBJECT_ID'] == terms_missing[0]][['SUBJECT_ID', 'term_id_english', 'term_english', 'term_id_spanish', 'term_spanish', 'term_id_port', 'term_port']]\n",
    "            if more_trans_combined.empty or term not in more_trans_combined['SUBJECT_ID'].to_list():\n",
    "                more_trans_combined = pd.concat([more_trans_combined, more_trans])\n",
    "\n",
    "    more_trans_combined = more_trans_combined.drop_duplicates()\n",
    "    more_trans_combined.to_clipboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1541261d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_terms_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3face9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "translations_df = translations_df.drop(['en_term', 'es_term', 'pt_term'], axis=1)\n",
    "translations_df = translations_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f94ae32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output_subjects = final_output_no_translations.merge(translations_df, how='left', left_on='identifier', right_on='identifier', indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e95bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_final = (\n",
    "    final_output_subjects[final_output_subjects['BoxId']== 'Box 3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a5ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_final[final_output_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c1d08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_final[final_output_columns].to_csv(\n",
    "    path_or_buf='./csv_files/output_file_v2_box2.csv',\n",
    "    index=False, header=dc_output_final,\n",
    "    quoting=csv.QUOTE_NONNUMERIC\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57e31a92",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "from gsheets import Sheets\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b36f31da",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "url = 'https://docs.google.com/spreadsheets/d/1LRbios7yQRo3aqCh0Es2Wiae_dicg_OtL-_yqP-Tb8I/edit#gid=1718343431'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d0350e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Create resusable lists for reference in data display or collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# lists used in the loading of the AAT Metadata\n",
    "narrow_list = ['identifier', 'media', 'subject', 'title', 'subjects', 'SUBJECT_ID_x', 'TERM_ID', 'join_concept', 'BoxId', 'color']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%run functions.ipynb"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "load_metadata()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1460d61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_49737/3168744551.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(file_path\n",
      "/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_49737/3168744551.py:2: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(file_path\n",
      "b'Skipping line 451800: expected 13 fields, saw 14\\n'\n",
      "/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_49737/3168744551.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path\n",
      "/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_49737/3168744551.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(file_path\n",
      "/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_49737/3168744551.py:2: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(file_path\n",
      "b'Skipping line 466042: expected 8 fields, saw 9\\nSkipping line 468123: expected 8 fields, saw 9\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AACR2_FLAG</th>\n",
       "      <th>DISPLAY_DATE</th>\n",
       "      <th>DISPLAY_NAME</th>\n",
       "      <th>DISPLAY_ORDER</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>HISTORIC_FLAG</th>\n",
       "      <th>OTHER_FLAGS</th>\n",
       "      <th>PREFERRED_x</th>\n",
       "      <th>START_DATE</th>\n",
       "      <th>SUBJECT_ID_x</th>\n",
       "      <th>...</th>\n",
       "      <th>LANGUAGE_CODE</th>\n",
       "      <th>PREFERRED_y</th>\n",
       "      <th>SUBJECT_ID_y</th>\n",
       "      <th>QUALIFIER</th>\n",
       "      <th>TERM_TYPE</th>\n",
       "      <th>PART_OF_SPEECH</th>\n",
       "      <th>LANG_STAT</th>\n",
       "      <th>full_concept</th>\n",
       "      <th>use_concept</th>\n",
       "      <th>join_concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300022903</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>N</td>\n",
       "      <td>300022903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UF</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>knives, gauge</td>\n",
       "      <td>knives, gauge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300022904</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>P</td>\n",
       "      <td>300022904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>PN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hand knives</td>\n",
       "      <td>hand knives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300022904</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>N</td>\n",
       "      <td>300022904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AD</td>\n",
       "      <td>SN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hand knife</td>\n",
       "      <td>hand knife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300022904</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>N</td>\n",
       "      <td>300022904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UF</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>knives, hand</td>\n",
       "      <td>knives, hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300022905</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>P</td>\n",
       "      <td>300022905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>PN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hawkbill knives</td>\n",
       "      <td>hawkbill knives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483186</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300430882</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>P</td>\n",
       "      <td>300430882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prophylactics</td>\n",
       "      <td>prophylactics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483187</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300434048</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>P</td>\n",
       "      <td>300434048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>PN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>styptic pencils</td>\n",
       "      <td>styptic pencils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483188</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300434776</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>P</td>\n",
       "      <td>300434776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>PN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tissues</td>\n",
       "      <td>tissues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483189</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300431243</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>P</td>\n",
       "      <td>300431243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>PN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>towelettes</td>\n",
       "      <td>towelettes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483190</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300432605</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>P</td>\n",
       "      <td>300432605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>PN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>washcloths</td>\n",
       "      <td>washcloths</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483191 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AACR2_FLAG DISPLAY_DATE DISPLAY_NAME  DISPLAY_ORDER END_DATE  \\\n",
       "0             NaN          NaN          NaN            3.0      NaN   \n",
       "1             NaN          NaN          NaN            1.0      NaN   \n",
       "2             NaN          NaN          NaN            2.0      NaN   \n",
       "3             NaN          NaN          NaN            3.0      NaN   \n",
       "4             NaN          NaN          NaN            1.0      NaN   \n",
       "...           ...          ...          ...            ...      ...   \n",
       "483186        NaN          NaN          NaN            1.0      NaN   \n",
       "483187        NaN          NaN          NaN            1.0      NaN   \n",
       "483188        NaN          NaN          NaN            1.0      NaN   \n",
       "483189        NaN          NaN          NaN            1.0      NaN   \n",
       "483190        NaN          NaN          NaN            1.0      NaN   \n",
       "\n",
       "       HISTORIC_FLAG OTHER_FLAGS PREFERRED_x  START_DATE SUBJECT_ID_x  ...  \\\n",
       "0                  C         NaN           V         NaN    300022903  ...   \n",
       "1                  C         NaN           P         NaN    300022904  ...   \n",
       "2                  C         NaN           V         NaN    300022904  ...   \n",
       "3                  C         NaN           V         NaN    300022904  ...   \n",
       "4                  C         NaN           P         NaN    300022905  ...   \n",
       "...              ...         ...         ...         ...          ...  ...   \n",
       "483186             C         NaN           P         NaN    300430882  ...   \n",
       "483187             C         NaN           P         NaN    300434048  ...   \n",
       "483188             C         NaN           P         NaN    300434776  ...   \n",
       "483189             C         NaN           P         NaN    300431243  ...   \n",
       "483190             C         NaN           P         NaN    300432605  ...   \n",
       "\n",
       "       LANGUAGE_CODE PREFERRED_y SUBJECT_ID_y QUALIFIER TERM_TYPE  \\\n",
       "0              70051           N    300022903       NaN        UF   \n",
       "1              70051           P    300022904       NaN         D   \n",
       "2              70051           N    300022904       NaN        AD   \n",
       "3              70051           N    300022904       NaN        UF   \n",
       "4              70051           P    300022905       NaN         D   \n",
       "...              ...         ...          ...       ...       ...   \n",
       "483186         70051           P    300430882       NaN         D   \n",
       "483187         70051           P    300434048       NaN         D   \n",
       "483188         70051           P    300434776       NaN         D   \n",
       "483189         70051           P    300431243       NaN         D   \n",
       "483190         70051           P    300432605       NaN         D   \n",
       "\n",
       "       PART_OF_SPEECH LANG_STAT full_concept      use_concept     join_concept  \n",
       "0                   U         U          NaN    knives, gauge    knives, gauge  \n",
       "1                  PN         U          NaN      hand knives      hand knives  \n",
       "2                  SN         U          NaN       hand knife       hand knife  \n",
       "3                   U         U          NaN     knives, hand     knives, hand  \n",
       "4                  PN         U          NaN  hawkbill knives  hawkbill knives  \n",
       "...               ...       ...          ...              ...              ...  \n",
       "483186              U         U          NaN    prophylactics    prophylactics  \n",
       "483187             PN         U          NaN  styptic pencils  styptic pencils  \n",
       "483188             PN         U          NaN          tissues          tissues  \n",
       "483189             PN         U          NaN       towelettes       towelettes  \n",
       "483190             PN         U          NaN       washcloths       washcloths  \n",
       "\n",
       "[483191 rows x 23 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_metadata()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf4b9a4",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the spreadsheet information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cbe2937a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# if HttpAccessTokenRefreshError, close everything and start over\n",
    "sheets = Sheets.from_files('~/client_secrets.json', '~/storage.json')\n",
    "s = sheets.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26195a3b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get the list of boxes containing metadata\n",
    "\n",
    "box_list = []\n",
    "box_list_sheets = s.sheets.titles()\n",
    "\n",
    "for b in box_list_sheets:\n",
    "    if 'Box' in b:\n",
    "        box_list.append(int(b[4:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f5ad0e",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Consider comma cases\n",
    "\n",
    "given that we'll parse the created Arquin metadata by comma, we need to handle cases where the subject term, aka concept, contains an internal comma (e.g. \"knives, gauge\"). These will need to be parsed carfully for two reasons:\n",
    "\n",
    "1.) The comma could falsely parse the concept\n",
    "\n",
    "2.) The individual components of the concept could be valid AAT terms, too... eg. \"knives, gauge\" Both \"knives\" and \"gauge\" are valid AAT terms while so is \"knives, gauge\". Knowing what the metata analyst intended in this case is highly difficult to determine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b82665de",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_49737/3168744551.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(file_path\n",
      "/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_49737/3168744551.py:2: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(file_path\n",
      "b'Skipping line 451800: expected 13 fields, saw 14\\n'\n",
      "/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_49737/3168744551.py:2: DtypeWarning: Columns (4) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path\n",
      "/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_49737/3168744551.py:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(file_path\n",
      "/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_49737/3168744551.py:2: FutureWarning: The warn_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
      "\n",
      "\n",
      "  data = pd.read_csv(file_path\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './AAT_Files/LANGUAGE_RELS.out'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[0;32mIn [11]\u001B[0m, in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0m concepts \u001B[38;5;241m=\u001B[39m \u001B[43mload_metadata\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_49737/62385621.py:8\u001B[0m, in \u001B[0;36mload_metadata\u001B[0;34m()\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;124;03m\"\"\"load the metadata that will be used\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03mfiles were downloaded from: http://aatdownloads.getty.edu/\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      7\u001B[0m terms \u001B[38;5;241m=\u001B[39m read_aat_terms(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./AAT_Files/TERM.out\u001B[39m\u001B[38;5;124m'\u001B[39m, terms_header_list, terms_dtype)\n\u001B[0;32m----> 8\u001B[0m lang_rels \u001B[38;5;241m=\u001B[39m \u001B[43mread_aat_terms\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./AAT_Files/LANGUAGE_RELS.out\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlang_rels_header_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlang_rel_dtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      9\u001B[0m concepts \u001B[38;5;241m=\u001B[39m (pd\u001B[38;5;241m.\u001B[39mmerge(terms, lang_rels, how \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124minner\u001B[39m\u001B[38;5;124m'\u001B[39m, on\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTERM_ID\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m     10\u001B[0m concepts[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfull_concept\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m (concepts\u001B[38;5;241m.\u001B[39mTERM \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m (\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m concepts\u001B[38;5;241m.\u001B[39mQUALIFIER \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m)\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m/var/folders/ts/9ppg2hqj4t5_9cslr1528y_m0000gp/T/ipykernel_49737/3168744551.py:2\u001B[0m, in \u001B[0;36mread_aat_terms\u001B[0;34m(file_path, names, data_types)\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mread_aat_terms\u001B[39m(file_path: \u001B[38;5;28mstr\u001B[39m, names: \u001B[38;5;28mlist\u001B[39m, data_types: \u001B[38;5;28mdict\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame:\n\u001B[0;32m----> 2\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile_path\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[43m                       \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msep\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;130;43;01m\\t\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\n\u001B[1;32m      4\u001B[0m \u001B[43m                       \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwarn_bad_lines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[1;32m      5\u001B[0m \u001B[43m                       \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43merror_bad_lines\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m      6\u001B[0m \u001B[43m                       \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnames\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnames\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m                       \u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdata_types\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[1;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[1;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[1;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[1;32m    310\u001B[0m     )\n\u001B[0;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[1;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m    666\u001B[0m     dialect,\n\u001B[1;32m    667\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[1;32m    677\u001B[0m )\n\u001B[1;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    572\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    574\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 575\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py:933\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    930\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m    932\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m--> 933\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1217\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1213\u001B[0m     mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1214\u001B[0m \u001B[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001B[39;00m\n\u001B[1;32m   1215\u001B[0m \u001B[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001B[39;00m\n\u001B[1;32m   1216\u001B[0m \u001B[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001B[39;00m\n\u001B[0;32m-> 1217\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[call-overload]\u001B[39;49;00m\n\u001B[1;32m   1218\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1219\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1220\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1221\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1222\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1223\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1224\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1225\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1226\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1227\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1228\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/pandas/io/common.py:789\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    784\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    785\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    786\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    787\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    788\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 789\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    793\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    796\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    797\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    798\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: './AAT_Files/LANGUAGE_RELS.out'"
     ]
    }
   ],
   "source": [
    "concepts = load_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d90d4dc",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# review the metadata for concepts containing a comma and return those as a list\n",
    "concepts_drop = concepts[concepts['use_concept'].notna()]\n",
    "concepts_search = concepts_drop[concepts_drop['use_concept'].str.contains(',')]\n",
    "concepts_comma = concepts_search['use_concept'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11bda417",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load the Metadata from Getty AAT\n",
    "\n",
    "Individual AAT Terms can be seen here:\n",
    "https://www.getty.edu/research/tools/vocabularies/aat/\n",
    "\n",
    "We use the .Out files available below for consuming the data - these are batch released so terms in the .Out files may note be availalbe on the AAT search (link above) or vice-versa:\n",
    "http://aatdownloads.getty.edu/\n",
    "\n",
    "Note that when we load files, we join the LANGUAGE_RELS.out and TERM.out files and combine the term and and the qualifier to create the \"subjects\" and \"join_concepts\"\n",
    "\n",
    "The join_concept ensures the case for the term is all lower case\n",
    "\n",
    "We also create a \"full_concept\" but doesn't handle the NULL case well and shouldn't be used for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9f870d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AACR2_FLAG</th>\n",
       "      <th>DISPLAY_DATE</th>\n",
       "      <th>DISPLAY_NAME</th>\n",
       "      <th>DISPLAY_ORDER</th>\n",
       "      <th>END_DATE</th>\n",
       "      <th>HISTORIC_FLAG</th>\n",
       "      <th>OTHER_FLAGS</th>\n",
       "      <th>PREFERRED_x</th>\n",
       "      <th>START_DATE</th>\n",
       "      <th>SUBJECT_ID_x</th>\n",
       "      <th>...</th>\n",
       "      <th>LANGUAGE_CODE</th>\n",
       "      <th>PREFERRED_y</th>\n",
       "      <th>SUBJECT_ID_y</th>\n",
       "      <th>QUALIFIER</th>\n",
       "      <th>TERM_TYPE</th>\n",
       "      <th>PART_OF_SPEECH</th>\n",
       "      <th>LANG_STAT</th>\n",
       "      <th>full_concept</th>\n",
       "      <th>use_concept</th>\n",
       "      <th>join_concept</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300022903</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>N</td>\n",
       "      <td>300022903</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UF</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>knives, gauge</td>\n",
       "      <td>knives, gauge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300022904</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>P</td>\n",
       "      <td>300022904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>PN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hand knives</td>\n",
       "      <td>hand knives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300022904</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>N</td>\n",
       "      <td>300022904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AD</td>\n",
       "      <td>SN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hand knife</td>\n",
       "      <td>hand knife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300022904</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>N</td>\n",
       "      <td>300022904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UF</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>knives, hand</td>\n",
       "      <td>knives, hand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300022905</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>P</td>\n",
       "      <td>300022905</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>PN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hawkbill knives</td>\n",
       "      <td>hawkbill knives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483188</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300430882</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>P</td>\n",
       "      <td>300430882</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>U</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>prophylactics</td>\n",
       "      <td>prophylactics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483189</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300434048</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>P</td>\n",
       "      <td>300434048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>PN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>styptic pencils</td>\n",
       "      <td>styptic pencils</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483190</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300434776</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>P</td>\n",
       "      <td>300434776</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>PN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tissues</td>\n",
       "      <td>tissues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483191</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300431243</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>P</td>\n",
       "      <td>300431243</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>PN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>towelettes</td>\n",
       "      <td>towelettes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483192</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>P</td>\n",
       "      <td>NaN</td>\n",
       "      <td>300432605</td>\n",
       "      <td>...</td>\n",
       "      <td>70051</td>\n",
       "      <td>P</td>\n",
       "      <td>300432605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>D</td>\n",
       "      <td>PN</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>washcloths</td>\n",
       "      <td>washcloths</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>483188 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AACR2_FLAG DISPLAY_DATE DISPLAY_NAME  DISPLAY_ORDER END_DATE  \\\n",
       "0             NaN          NaN          NaN            3.0      NaN   \n",
       "1             NaN          NaN          NaN            1.0      NaN   \n",
       "2             NaN          NaN          NaN            2.0      NaN   \n",
       "3             NaN          NaN          NaN            3.0      NaN   \n",
       "4             NaN          NaN          NaN            1.0      NaN   \n",
       "...           ...          ...          ...            ...      ...   \n",
       "483188        NaN          NaN          NaN            1.0      NaN   \n",
       "483189        NaN          NaN          NaN            1.0      NaN   \n",
       "483190        NaN          NaN          NaN            1.0      NaN   \n",
       "483191        NaN          NaN          NaN            1.0      NaN   \n",
       "483192        NaN          NaN          NaN            1.0      NaN   \n",
       "\n",
       "       HISTORIC_FLAG OTHER_FLAGS PREFERRED_x  START_DATE SUBJECT_ID_x  ...  \\\n",
       "0                  C         NaN           V         NaN    300022903  ...   \n",
       "1                  C         NaN           P         NaN    300022904  ...   \n",
       "2                  C         NaN           V         NaN    300022904  ...   \n",
       "3                  C         NaN           V         NaN    300022904  ...   \n",
       "4                  C         NaN           P         NaN    300022905  ...   \n",
       "...              ...         ...         ...         ...          ...  ...   \n",
       "483188             C         NaN           P         NaN    300430882  ...   \n",
       "483189             C         NaN           P         NaN    300434048  ...   \n",
       "483190             C         NaN           P         NaN    300434776  ...   \n",
       "483191             C         NaN           P         NaN    300431243  ...   \n",
       "483192             C         NaN           P         NaN    300432605  ...   \n",
       "\n",
       "       LANGUAGE_CODE PREFERRED_y SUBJECT_ID_y QUALIFIER TERM_TYPE  \\\n",
       "0              70051           N    300022903       NaN        UF   \n",
       "1              70051           P    300022904       NaN         D   \n",
       "2              70051           N    300022904       NaN        AD   \n",
       "3              70051           N    300022904       NaN        UF   \n",
       "4              70051           P    300022905       NaN         D   \n",
       "...              ...         ...          ...       ...       ...   \n",
       "483188         70051           P    300430882       NaN         D   \n",
       "483189         70051           P    300434048       NaN         D   \n",
       "483190         70051           P    300434776       NaN         D   \n",
       "483191         70051           P    300431243       NaN         D   \n",
       "483192         70051           P    300432605       NaN         D   \n",
       "\n",
       "       PART_OF_SPEECH LANG_STAT full_concept      use_concept     join_concept  \n",
       "0                   U         U          NaN    knives, gauge    knives, gauge  \n",
       "1                  PN         U          NaN      hand knives      hand knives  \n",
       "2                  SN         U          NaN       hand knife       hand knife  \n",
       "3                   U         U          NaN     knives, hand     knives, hand  \n",
       "4                  PN         U          NaN  hawkbill knives  hawkbill knives  \n",
       "...               ...       ...          ...              ...              ...  \n",
       "483188              U         U          NaN    prophylactics    prophylactics  \n",
       "483189             PN         U          NaN  styptic pencils  styptic pencils  \n",
       "483190             PN         U          NaN          tissues          tissues  \n",
       "483191             PN         U          NaN       towelettes       towelettes  \n",
       "483192             PN         U          NaN       washcloths       washcloths  \n",
       "\n",
       "[483188 rows x 23 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concepts[concepts['join_concept'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1737bdfa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete, imported 69 boxes\n"
     ]
    }
   ],
   "source": [
    "# load all the boxes and split them\n",
    "for i, box_number in enumerate(box_list):\n",
    "    df = return_box(box_number)\n",
    "    clear_output(wait=True)\n",
    "    print(f\"working on Box {box_number}\")\n",
    "    \n",
    "    try:\n",
    "        df = split_df(df)\n",
    "    except:\n",
    "        print(f'failed to split df for box number {box_number}')\n",
    "\n",
    "    if i+1 == 1:\n",
    "        df_combined = df\n",
    "    else:\n",
    "        df_combined = combine_boxes(df_combined, df)\n",
    " \n",
    "clear_output(wait=True)    \n",
    "\n",
    "df = df_combined\n",
    "df['subjects'] = df['subjects'].replace(r'^\\s*$', np.nan, regex=True)\n",
    "df = df.dropna(subset=['subjects'])\n",
    "print(f'complete, imported {i+1} boxes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ac88d2a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# join the df with the concepts\n",
    "df = pd.merge(df, concepts, how=\"left\", on='join_concept')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f04f18c0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get the boxid\n",
    "df['boxid_temp'] = df['media'].str.extract(r\"(_0\\d+_)\")\n",
    "df = df[df['media'].notna()]\n",
    "df['boxid_temp'] = df['boxid_temp'].str.replace(\"_\",\"\")\n",
    "df['boxid_temp'] = pd.to_numeric(df['boxid_temp'], errors='coerce')\n",
    "df = df.dropna(subset=['boxid_temp'])\n",
    "df['boxid_temp'] = df['boxid_temp'].astype('int')\n",
    "df['boxid_temp'] = df['boxid_temp'].astype('str')\n",
    "df['BoxId'] = 'Box '+df['boxid_temp']\n",
    "df.drop('boxid_temp', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b9330",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Add in Tab Color\n",
    "\n",
    "The colors of each tab are identified in 'get_spreadsheets_color.ipynb'. That script creates a CSV file and that is read in and added to the df_combined object\n",
    "\n",
    "Read in the color match file created here:\n",
    "http://localhost:8888/notebooks/get_spreadsheets.ipynb\n",
    "\n",
    "use that to create the list of titles based on color of the tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be0ab58c",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "color_match_df = pd.read_csv('csv_files/color_match', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14e7f629",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.merge(df, color_match_df, on='BoxId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "de232915",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# get all the unique media IDs where media is not NA \n",
    "df_medias = df.media.dropna().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a1d2ae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Run the full flow through in the following cell. Be sure to DELETE the unmatched_subjects_v2.csv file before staring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa7395ed",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16221 of 16222: search_media = Arquin_069_0217.jpg\n"
     ]
    }
   ],
   "source": [
    "df_medias_len = len(df_medias)\n",
    "\n",
    "for i, search_media in enumerate(df_medias):\n",
    "    clear_output(wait=True) \n",
    "    print(f'{i} of {df_medias_len}: search_media = {search_media}')\n",
    "#     x = input('step 1: press any key to continue... ')\n",
    "    \n",
    "    try_match_neg = None\n",
    "    try_match_pos = None\n",
    "    cancel_repeat = False\n",
    "    concepts_found_pos = []\n",
    "    concepts_found_neg = []\n",
    "    \n",
    "    df_subjects = df[df['media'] == search_media].join_concept.to_list()\n",
    "    df_media_no_match = df[df['media'] == search_media].loc[df['SUBJECT_ID_x'].isna()]\n",
    "#     print(f'{i}: search_media = {search_media}, df_media_no_match = {df_media_no_match}')\n",
    "#     x = input('press any key to continue... ')\n",
    "    \n",
    "    if len(df_media_no_match) > 0:\n",
    "#         print(f'{i}: search_media = {search_media}, passed len(df_media_no_match) > 0 ')\n",
    "#         x = input('step 2: press any key to continue... ')\n",
    "        \n",
    "        \n",
    "        no_match = df_media_no_match.join_concept.to_list()\n",
    "#         print(f'{i}: search_media: {search_media}, no_match = {no_match}')\n",
    "        \n",
    "        for i, unmatched in enumerate(no_match):\n",
    "#             print(f'{i}: unmatched = {unmatched}, remove_con = {remove_con}')\n",
    "#             x = input('step 3: press any key to continue... ')\n",
    "#             if cancel_repeat == True:\n",
    "#                 break\n",
    "            \n",
    "            if i > 0:\n",
    "                if unmatched == remove_this_con:\n",
    "#                     print(f'already removed {remove_con} from  {search_media}')\n",
    "#                     x = input(f'step 4: it worked! Continue? (press x)')\n",
    "#                     cancel_repeat = True\n",
    "                    break\n",
    "            \n",
    "            pos = False\n",
    "            neg = False\n",
    "            new_concept = None\n",
    "            pop_index = None\n",
    "            \n",
    "            no_match_index = df_subjects.index(unmatched)\n",
    "#             print(f'step 5: {i+1}: unmatched concept is: \"{unmatched}\" and its index is \"{no_match_index}\" out of {len(df_subjects)-1}')\n",
    "            \n",
    "            if no_match_index > 0:\n",
    "                try_match_neg = df_subjects[no_match_index-1]+', '+df_subjects[no_match_index]\n",
    "                concepts_found_pos = concepts.loc[concepts['join_concept'] == try_match_neg]\n",
    "                if len(concepts_found_pos) > 0:\n",
    "                    pos = True\n",
    "#                     print(f'pos is {pos}')\n",
    "            if no_match_index < len(df_subjects)-1:\n",
    "                try_match_pos = df_subjects[no_match_index]+', '+df_subjects[no_match_index+1]\n",
    "                concepts_found_neg = concepts.loc[concepts['join_concept'] == try_match_pos]\n",
    "                if len(concepts_found_neg) > 0:\n",
    "                    neg = True\n",
    "#                     print(f'neg is {neg}')\n",
    "#             print(f'try_match_neg = \"{try_match_neg}\"\\ntry_match_pos = \"{try_match_pos}\"')\n",
    "            \n",
    "            try:\n",
    "                if len(concepts_found_pos) == 1:\n",
    "                    new_concept = concepts_found_pos.join_concept.to_list()[0]\n",
    "                    \n",
    "                        \n",
    "            except (NameError):\n",
    "                pass\n",
    "            try:\n",
    "                if len(concepts_found_neg) == 1:\n",
    "                    new_concept = concepts_found_neg.join_concept.to_list()[0]\n",
    "            except (NameError):\n",
    "                pass\n",
    "            try:\n",
    "                if (len(concepts_found_pos) > 0) & (len(concepts_found_neg) > 0):\n",
    "                    print('too many matches!')\n",
    "                    pass\n",
    "            except (NameError):\n",
    "                pass\n",
    "            try:\n",
    "                if (len(concepts_found_pos) == 0) & (len(concepts_found_neg) == 0):\n",
    "                    unmatched_df = df[(df['media'] == search_media) \n",
    "                                      & (df['join_concept'] == unmatched)][narrow_list]\n",
    "                    add_to_not_found(unmatched_df)\n",
    "            except (NameError):\n",
    "                pass\n",
    "            \n",
    "            remove_con = df_subjects[no_match_index]\n",
    "            remove_this_con_index = 0\n",
    "            \n",
    "            if pos:\n",
    "                remove_this_con_index = no_match_index-1\n",
    "            if neg:\n",
    "                remove_this_con_index = no_match_index+1\n",
    "\n",
    "            if pos | neg:\n",
    "                remove_this_con = df_subjects[remove_this_con_index]\n",
    "\n",
    "                df = df.drop(\n",
    "                    df[((df['media'] == search_media) & \n",
    "                                      (df['join_concept'] == remove_this_con)\n",
    "                                     )].index\n",
    "                )\n",
    "            \n",
    "    #     determine the location in the index of the concept to be removed\n",
    "                pop_index = df.loc[(df['media'] == search_media) & (df['join_concept'] == remove_con)].index\n",
    "    #     remove the concept found at that index\n",
    "                df.at[pop_index[0], 'join_concept'] = new_concept\n",
    "                df.at[pop_index[0], 'subjects'] = new_concept\n",
    "                df.at[pop_index[0], 'SUBJECT_ID_x'] = concepts.at[concepts.loc[concepts['join_concept'] == new_concept].index[0], 'SUBJECT_ID_x']\n",
    "                df.at[pop_index[0], 'TERM_ID'] = concepts.at[concepts.loc[concepts['join_concept'] == new_concept].index[0], 'TERM_ID']\n",
    "\n",
    "            print(f'new_concept = {new_concept}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}